{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Sentiment140 Data Set\n",
    "This notebook processes the Sentiment140 data set to prepare the tweets for using with the model. The processing removes URLs, mentions, punctuation and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import preprocessor\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "SENTIMENT140_FILE = 'training.1600000.processed.noemoticon.csv'\n",
    "CONTRACTIONS_FILE = 'contractions.json'\n",
    "CLEAN_SENTIMENT140_FILE = 'sentiment140_clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, SENTIMENT140_FILE),\n",
    "                 encoding='latin-1',\n",
    "                 names=['target', 'ids', 'date', 'flag', 'user', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is perfectly balanced, so no issues there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the tweets\n",
    "Convert everything to lowercase, expand contractions and remove punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, CONTRACTIONS_FILE), 'r') as file:\n",
    "    contractions = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {key.lower(): value.lower() for key, value in contractions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ain't\": 'am not',\n",
       " \"aren't\": 'are not',\n",
       " \"can't\": 'can not',\n",
       " \"can't've\": 'can not have',\n",
       " \"'cause\": 'because',\n",
       " \"could've\": 'could have',\n",
       " \"couldn't\": 'could not',\n",
       " \"couldn't've\": 'could not have',\n",
       " \"didn't\": 'did not',\n",
       " \"doesn't\": 'does not',\n",
       " \"don't\": 'do not',\n",
       " \"hadn't\": 'had not',\n",
       " \"hadn't've\": 'had not have',\n",
       " \"hasn't\": 'has not',\n",
       " \"haven't\": 'have not',\n",
       " \"he'd\": 'he would',\n",
       " \"he'd've\": 'he would have',\n",
       " \"he'll\": 'he will',\n",
       " \"he'll've\": 'he will have',\n",
       " \"he's\": 'he is',\n",
       " \"how'd\": 'how did',\n",
       " \"how'd'y\": 'how do you',\n",
       " \"how'll\": 'how will',\n",
       " \"how's\": 'how is',\n",
       " \"i'd\": 'i would',\n",
       " \"i'd've\": 'i would have',\n",
       " \"i'll\": 'i will',\n",
       " \"i'll've\": 'i will have',\n",
       " \"i'm\": 'i am',\n",
       " \"i've\": 'i have',\n",
       " \"isn't\": 'is not',\n",
       " \"it'd\": 'it had',\n",
       " \"it'd've\": 'it would have',\n",
       " \"it'll\": 'it will',\n",
       " \"it'll've\": 'it will have',\n",
       " \"it's\": 'it is',\n",
       " \"let's\": 'let us',\n",
       " \"ma'am\": 'madam',\n",
       " \"mayn't\": 'may not',\n",
       " \"might've\": 'might have',\n",
       " \"mightn't\": 'might not',\n",
       " \"mightn't've\": 'might not have',\n",
       " \"must've\": 'must have',\n",
       " \"mustn't\": 'must not',\n",
       " \"mustn't've\": 'must not have',\n",
       " \"needn't\": 'need not',\n",
       " \"needn't've\": 'need not have',\n",
       " \"o'clock\": 'of the clock',\n",
       " \"oughtn't\": 'ought not',\n",
       " \"oughtn't've\": 'ought not have',\n",
       " \"shan't\": 'shall not',\n",
       " \"sha'n't\": 'shall not',\n",
       " \"shan't've\": 'shall not have',\n",
       " \"she'd\": 'she would',\n",
       " \"she'd've\": 'she would have',\n",
       " \"she'll\": 'she will',\n",
       " \"she'll've\": 'she will have',\n",
       " \"she's\": 'she is',\n",
       " \"should've\": 'should have',\n",
       " \"shouldn't\": 'should not',\n",
       " \"shouldn't've\": 'should not have',\n",
       " \"so've\": 'so have',\n",
       " \"so's\": 'so is',\n",
       " \"that'd\": 'that would',\n",
       " \"that'd've\": 'that would have',\n",
       " \"that's\": 'that is',\n",
       " \"there'd\": 'there had',\n",
       " \"there'd've\": 'there would have',\n",
       " \"there's\": 'there is',\n",
       " \"they'd\": 'they would',\n",
       " \"they'd've\": 'they would have',\n",
       " \"they'll\": 'they will',\n",
       " \"they'll've\": 'they will have',\n",
       " \"they're\": 'they are',\n",
       " \"they've\": 'they have',\n",
       " \"to've\": 'to have',\n",
       " \"wasn't\": 'was not',\n",
       " \"we'd\": 'we had',\n",
       " \"we'd've\": 'we would have',\n",
       " \"we'll\": 'we will',\n",
       " \"we'll've\": 'we will have',\n",
       " \"we're\": 'we are',\n",
       " \"we've\": 'we have',\n",
       " \"weren't\": 'were not',\n",
       " \"what'll\": 'what will',\n",
       " \"what'll've\": 'what will have',\n",
       " \"what're\": 'what are',\n",
       " \"what's\": 'what is',\n",
       " \"what've\": 'what have',\n",
       " \"when's\": 'when is',\n",
       " \"when've\": 'when have',\n",
       " \"where'd\": 'where did',\n",
       " \"where's\": 'where is',\n",
       " \"where've\": 'where have',\n",
       " \"who'll\": 'who will',\n",
       " \"who'll've\": 'who will have',\n",
       " \"who's\": 'who is',\n",
       " \"who've\": 'who have',\n",
       " \"why's\": 'why is',\n",
       " \"why've\": 'why have',\n",
       " \"will've\": 'will have',\n",
       " \"won't\": 'will not',\n",
       " \"won't've\": 'will not have',\n",
       " \"would've\": 'would have',\n",
       " \"wouldn't\": 'would not',\n",
       " \"wouldn't've\": 'would not have',\n",
       " \"y'all\": 'you all',\n",
       " \"y'alls\": 'you alls',\n",
       " \"y'all'd\": 'you all would',\n",
       " \"y'all'd've\": 'you all would have',\n",
       " \"y'all're\": 'you all are',\n",
       " \"y'all've\": 'you all have',\n",
       " \"you'd\": 'you had',\n",
       " \"you'd've\": 'you would have',\n",
       " \"you'll\": 'you will',\n",
       " \"you'll've\": 'you will have',\n",
       " \"you're\": 'you are',\n",
       " \"you've\": 'you have'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to replace the contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "def expand_contractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am not'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"i'm not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform the cleaning of a single tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    # Remove URLs and mentions\n",
    "    tweet = preprocessor.clean(tweet)\n",
    "    # Remove bad symbols\n",
    "    tweet = BAD_SYMBOLS_RE.sub(' ', tweet)\n",
    "     # Expand contractions\n",
    "    tweet = expand_contractions(tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = ' '.join(re.sub(\"([^0-9A-Za-z \\t])\", \" \", tweet).split())\n",
    "    # For RNN models such as LSTM we do not remove stopwords\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the cleaning function to all tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode the labels\n",
    "Recode the labels in a slightly more intuitive way: 0 for negative and 1 for positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].replace({4: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data set and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1574145</th>\n",
       "      <td>1</td>\n",
       "      <td>2189197570</td>\n",
       "      <td>Mon Jun 15 23:28:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pattylOoves</td>\n",
       "      <td>@yayitsa hey hey what about u and jose????...umm</td>\n",
       "      <td>hey hey what about u and jose umm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656615</th>\n",
       "      <td>0</td>\n",
       "      <td>2240575390</td>\n",
       "      <td>Fri Jun 19 09:54:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Kaitikins</td>\n",
       "      <td>@tiffaknee  sorry....?</td>\n",
       "      <td>sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253508</th>\n",
       "      <td>1</td>\n",
       "      <td>1996915756</td>\n",
       "      <td>Mon Jun 01 15:55:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AngelicVampira</td>\n",
       "      <td>@baneen glad you had a good time  i think we a...</td>\n",
       "      <td>glad you had a good time i think we all apprec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586982</th>\n",
       "      <td>1</td>\n",
       "      <td>2190874142</td>\n",
       "      <td>Tue Jun 16 03:57:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alexaawasheree</td>\n",
       "      <td>getting ready to leave for my class trip... to...</td>\n",
       "      <td>getting ready to leave for my class trip today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187285</th>\n",
       "      <td>0</td>\n",
       "      <td>1968614329</td>\n",
       "      <td>Fri May 29 21:49:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jbxbaybee</td>\n",
       "      <td>im in serious need of ice cream!</td>\n",
       "      <td>im in serious need of ice cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "1574145       1  2189197570  Mon Jun 15 23:28:07 PDT 2009  NO_QUERY   \n",
       "656615        0  2240575390  Fri Jun 19 09:54:40 PDT 2009  NO_QUERY   \n",
       "1253508       1  1996915756  Mon Jun 01 15:55:23 PDT 2009  NO_QUERY   \n",
       "1586982       1  2190874142  Tue Jun 16 03:57:48 PDT 2009  NO_QUERY   \n",
       "187285        0  1968614329  Fri May 29 21:49:08 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \\\n",
       "1574145     pattylOoves  @yayitsa hey hey what about u and jose????...umm    \n",
       "656615        Kaitikins                             @tiffaknee  sorry....?   \n",
       "1253508  AngelicVampira  @baneen glad you had a good time  i think we a...   \n",
       "1586982  alexaawasheree  getting ready to leave for my class trip... to...   \n",
       "187285        jbxbaybee                  im in serious need of ice cream!    \n",
       "\n",
       "                                                clean_text  \n",
       "1574145                  hey hey what about u and jose umm  \n",
       "656615                                               sorry  \n",
       "1253508  glad you had a good time i think we all apprec...  \n",
       "1586982  getting ready to leave for my class trip today...  \n",
       "187285                     im in serious need of ice cream  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['target', 'clean_text']].to_csv(os.path.join(DATA_DIR, CLEAN_SENTIMENT140_FILE), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
