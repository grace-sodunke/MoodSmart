{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Sentiment140 Data Set\n",
    "This notebook processes the Sentiment140 data set to prepare the tweets for using with the model. The processing removes URLs, mentions, punctuation and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import preprocessor\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "SENTIMENT140_FILE = 'training.1600000.processed.noemoticon.csv'\n",
    "CONTRACTIONS_FILE = 'contractions.json'\n",
    "CLEAN_SENTIMENT140_FILE = 'sentiment140_clean.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, SENTIMENT140_FILE),\n",
    "                 encoding='latin-1',\n",
    "                 names=['target', 'ids', 'date', 'flag', 'user', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his facebook by ...  \n",
       "2         mattycus  @kenichan i dived many times for the ball. man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is perfectly balanced, so no issues there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the tweets\n",
    "Convert everything to lowercase, expand contractions and remove punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, CONTRACTIONS_FILE), 'r') as file:\n",
    "    contractions = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {key.lower(): value.lower() for key, value in contractions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ain't\": 'am not',\n",
       " \"aren't\": 'are not',\n",
       " \"can't\": 'can not',\n",
       " \"can't've\": 'can not have',\n",
       " \"'cause\": 'because',\n",
       " \"could've\": 'could have',\n",
       " \"couldn't\": 'could not',\n",
       " \"couldn't've\": 'could not have',\n",
       " \"didn't\": 'did not',\n",
       " \"doesn't\": 'does not',\n",
       " \"don't\": 'do not',\n",
       " \"hadn't\": 'had not',\n",
       " \"hadn't've\": 'had not have',\n",
       " \"hasn't\": 'has not',\n",
       " \"haven't\": 'have not',\n",
       " \"he'd\": 'he would',\n",
       " \"he'd've\": 'he would have',\n",
       " \"he'll\": 'he will',\n",
       " \"he'll've\": 'he will have',\n",
       " \"he's\": 'he is',\n",
       " \"how'd\": 'how did',\n",
       " \"how'd'y\": 'how do you',\n",
       " \"how'll\": 'how will',\n",
       " \"how's\": 'how is',\n",
       " \"i'd\": 'i would',\n",
       " \"i'd've\": 'i would have',\n",
       " \"i'll\": 'i will',\n",
       " \"i'll've\": 'i will have',\n",
       " \"i'm\": 'i am',\n",
       " \"i've\": 'i have',\n",
       " \"isn't\": 'is not',\n",
       " \"it'd\": 'it had',\n",
       " \"it'd've\": 'it would have',\n",
       " \"it'll\": 'it will',\n",
       " \"it'll've\": 'it will have',\n",
       " \"it's\": 'it is',\n",
       " \"let's\": 'let us',\n",
       " \"ma'am\": 'madam',\n",
       " \"mayn't\": 'may not',\n",
       " \"might've\": 'might have',\n",
       " \"mightn't\": 'might not',\n",
       " \"mightn't've\": 'might not have',\n",
       " \"must've\": 'must have',\n",
       " \"mustn't\": 'must not',\n",
       " \"mustn't've\": 'must not have',\n",
       " \"needn't\": 'need not',\n",
       " \"needn't've\": 'need not have',\n",
       " \"o'clock\": 'of the clock',\n",
       " \"oughtn't\": 'ought not',\n",
       " \"oughtn't've\": 'ought not have',\n",
       " \"shan't\": 'shall not',\n",
       " \"sha'n't\": 'shall not',\n",
       " \"shan't've\": 'shall not have',\n",
       " \"she'd\": 'she would',\n",
       " \"she'd've\": 'she would have',\n",
       " \"she'll\": 'she will',\n",
       " \"she'll've\": 'she will have',\n",
       " \"she's\": 'she is',\n",
       " \"should've\": 'should have',\n",
       " \"shouldn't\": 'should not',\n",
       " \"shouldn't've\": 'should not have',\n",
       " \"so've\": 'so have',\n",
       " \"so's\": 'so is',\n",
       " \"that'd\": 'that would',\n",
       " \"that'd've\": 'that would have',\n",
       " \"that's\": 'that is',\n",
       " \"there'd\": 'there had',\n",
       " \"there'd've\": 'there would have',\n",
       " \"there's\": 'there is',\n",
       " \"they'd\": 'they would',\n",
       " \"they'd've\": 'they would have',\n",
       " \"they'll\": 'they will',\n",
       " \"they'll've\": 'they will have',\n",
       " \"they're\": 'they are',\n",
       " \"they've\": 'they have',\n",
       " \"to've\": 'to have',\n",
       " \"wasn't\": 'was not',\n",
       " \"we'd\": 'we had',\n",
       " \"we'd've\": 'we would have',\n",
       " \"we'll\": 'we will',\n",
       " \"we'll've\": 'we will have',\n",
       " \"we're\": 'we are',\n",
       " \"we've\": 'we have',\n",
       " \"weren't\": 'were not',\n",
       " \"what'll\": 'what will',\n",
       " \"what'll've\": 'what will have',\n",
       " \"what're\": 'what are',\n",
       " \"what's\": 'what is',\n",
       " \"what've\": 'what have',\n",
       " \"when's\": 'when is',\n",
       " \"when've\": 'when have',\n",
       " \"where'd\": 'where did',\n",
       " \"where's\": 'where is',\n",
       " \"where've\": 'where have',\n",
       " \"who'll\": 'who will',\n",
       " \"who'll've\": 'who will have',\n",
       " \"who's\": 'who is',\n",
       " \"who've\": 'who have',\n",
       " \"why's\": 'why is',\n",
       " \"why've\": 'why have',\n",
       " \"will've\": 'will have',\n",
       " \"won't\": 'will not',\n",
       " \"won't've\": 'will not have',\n",
       " \"would've\": 'would have',\n",
       " \"wouldn't\": 'would not',\n",
       " \"wouldn't've\": 'would not have',\n",
       " \"y'all\": 'you all',\n",
       " \"y'alls\": 'you alls',\n",
       " \"y'all'd\": 'you all would',\n",
       " \"y'all'd've\": 'you all would have',\n",
       " \"y'all're\": 'you all are',\n",
       " \"y'all've\": 'you all have',\n",
       " \"you'd\": 'you had',\n",
       " \"you'd've\": 'you would have',\n",
       " \"you'll\": 'you will',\n",
       " \"you'll've\": 'you will have',\n",
       " \"you're\": 'you are',\n",
       " \"you've\": 'you have'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to replace the contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "def expand_contractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am not'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"i'm not\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform the cleaning of a single tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    # Remove URLs and mentions\n",
    "    tweet = preprocessor.clean(tweet)\n",
    "    # Remove bad symbols\n",
    "    tweet = BAD_SYMBOLS_RE.sub(' ', tweet)\n",
    "     # Expand contractions\n",
    "    tweet = expandContractions(tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = ' '.join(re.sub(\"([^0-9A-Za-z \\t])\", \" \", tweet).split())\n",
    "    # For RNN models such as LSTM we do not remove stopwords\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data set and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111994</th>\n",
       "      <td>0</td>\n",
       "      <td>1825303411</td>\n",
       "      <td>Sun May 17 05:11:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>msnomer</td>\n",
       "      <td>i sneezed all over my keyboard</td>\n",
       "      <td>i sneezed all over my keyboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874670</th>\n",
       "      <td>4</td>\n",
       "      <td>1680130027</td>\n",
       "      <td>Sat May 02 10:58:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alainsaffel</td>\n",
       "      <td>i've been explaining twitter to people at the ...</td>\n",
       "      <td>i ve been elaining twitter to people at the bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514847</th>\n",
       "      <td>4</td>\n",
       "      <td>2175530328</td>\n",
       "      <td>Mon Jun 15 01:14:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>captainjack63</td>\n",
       "      <td>@sylvie7 good to hear your studying like mad. ...</td>\n",
       "      <td>good to hear your studying like mad new locati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844075</th>\n",
       "      <td>4</td>\n",
       "      <td>1563990074</td>\n",
       "      <td>Mon Apr 20 01:12:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kisvirag</td>\n",
       "      <td>@theitalianjob: az se rossz</td>\n",
       "      <td>az se rossz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247867</th>\n",
       "      <td>4</td>\n",
       "      <td>1995636996</td>\n",
       "      <td>Mon Jun 01 13:48:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scott_welch</td>\n",
       "      <td>@heathbriggs30 yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "111994        0  1825303411  Sun May 17 05:11:23 PDT 2009  NO_QUERY   \n",
       "874670        4  1680130027  Sat May 02 10:58:25 PDT 2009  NO_QUERY   \n",
       "1514847       4  2175530328  Mon Jun 15 01:14:51 PDT 2009  NO_QUERY   \n",
       "844075        4  1563990074  Mon Apr 20 01:12:55 PDT 2009  NO_QUERY   \n",
       "1247867       4  1995636996  Mon Jun 01 13:48:32 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \\\n",
       "111994         msnomer                    i sneezed all over my keyboard    \n",
       "874670     alainsaffel  i've been explaining twitter to people at the ...   \n",
       "1514847  captainjack63  @sylvie7 good to hear your studying like mad. ...   \n",
       "844075        kisvirag                       @theitalianjob: az se rossz    \n",
       "1247867    scott_welch                                @heathbriggs30 yes    \n",
       "\n",
       "                                                clean_text  \n",
       "111994                      i sneezed all over my keyboard  \n",
       "874670   i ve been elaining twitter to people at the bu...  \n",
       "1514847  good to hear your studying like mad new locati...  \n",
       "844075                                         az se rossz  \n",
       "1247867                                                yes  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR, CLEAN_SENTIMENT140_FILE), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
